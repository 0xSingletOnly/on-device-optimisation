# On Device Optimisation
Warning: Work in progress!!!

Trying to figure out what is the most efficient way that I can run a LLM locally on my current stack, which includes:
- MacBook Pro M1 16GB
